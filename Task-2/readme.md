# ‚ù§Ô∏è Heart Disease Prediction ‚Äî Edulumos Internship (Task 02)

> **Comprehensive README** for the Heart Disease Prediction project. This README is written to be GitHub-ready and suitable for sharing in internship reports, GitHub repositories, and documentation.

---

## üöÄ Project Overview

This project builds a **machine learning system** to predict whether a patient has heart disease using clinical and demographic features. The final deliverable is a **Logistic Regression** model (saved as a `.pkl` artifact) chosen because the internship's task permits simpler, interpretable models.

**Goals:**
- Explore and clean the dataset
- Engineer and scale features
- Train and evaluate classification models
- Select the best allowed model (Logistic Regression)
- Save a production-ready artifact (model + scaler + feature list)
- Produce clear visualizations and a reproducible workflow

---

## üìÅ Repository Structure

```
HeartDiseasePredictor/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ heart_disease.csv                # raw dataset (rename as needed)
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ HeartDisease_Model.ipynb         # Jupyter notebook with code, EDA, and analysis
‚îú‚îÄ‚îÄ model/
‚îÇ   ‚îî‚îÄ‚îÄ HeartDisease_LogisticModel.pkl   # saved model artifact (joblib)
‚îú‚îÄ‚îÄ images/
‚îÇ   ‚îú‚îÄ‚îÄ roc_curve.png
‚îÇ   ‚îî‚îÄ‚îÄ confusion_matrix.png
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ README.md                             # this file
‚îî‚îÄ‚îÄ LICENSE
```

> **Note:** Some filenames in your environment (e.g. uploaded CSV) may have autogenerated names ‚Äî rename them to `heart_disease.csv` for clarity before committing.

---

## üìò Background & Motivation

Cardiovascular disease is a leading cause of death worldwide. Early detection of heart disease risk enables timely medical intervention and better outcomes. Machine learning models can help identify high-risk patients using routinely collected clinical features.

This project demonstrates the end-to-end ML pipeline on a clinical dataset, focusing on **interpretability** and **reproducibility**.

---

## üßæ Dataset

**Source:** Provided as part of the internship (a clinical-style CSV). Typical columns include (but are not limited to):

- `age` ‚Äî age of the patient
- `sex` ‚Äî 1 = male, 0 = female
- `cp` ‚Äî chest pain type
- `trestbps` ‚Äî resting blood pressure
- `chol` ‚Äî serum cholesterol
- `fbs` ‚Äî fasting blood sugar > 120 mg/dl
- `restecg` ‚Äî resting ECG results
- `thalach` ‚Äî max heart rate achieved
- `exang` ‚Äî exercise induced angina (1 = yes)
- `oldpeak` ‚Äî ST depression induced by exercise
- `slope` ‚Äî slope of peak exercise ST segment
- `ca` ‚Äî number of major vessels colored by fluoroscopy
- `thal` ‚Äî thallium stress test results
- `target` ‚Äî 1 = disease, 0 = no disease (target label)

> If your dataset uses different column names, update the notebook and code accordingly.

---

## üßπ Data Cleaning & Preprocessing

Key steps performed in the notebook:

1. **Load the CSV** using `pandas`.
2. **Inspect missing values** and data types (`df.info()`, `df.describe()`, `df.isnull().sum()`).
3. **Simple imputation:** numeric columns filled using column mean where necessary (`df.fillna(df.mean())`).
   - For categorical string columns, map common text to numeric codes or use one-hot encoding.
4. **Train / Test split:** `train_test_split` with `random_state=42` and `test_size=0.2`.
5. **Feature scaling:** `StandardScaler` applied to features before Logistic Regression.

Notes: for reproducibility, always use the same random seed. More advanced imputation (KNN, iterative) can be added later.

---

## üß™ Models Trained (for comparison)

Although the final submission requires a simple model, the notebook compares multiple models to show evaluation:

- **Logistic Regression** (final model) ‚Äî interpretable, robust, and allowed by the internship task.
- **Decision Tree** (baseline) ‚Äî intuitive but prone to overfitting.
- **Random Forest** ‚Äî powerful and often used in practice, included only for comparison when allowed; **not used** as final model if task restricts it.

---

## üìà Evaluation Metrics

For binary medical classification, a range of metrics were used to provide a full performance picture:

- **Accuracy** ‚Äî overall correct predictions
- **Precision** ‚Äî proportion of predicted positives that are true positives
- **Recall (Sensitivity)** ‚Äî proportion of actual positives correctly identified
- **F1-score** ‚Äî harmonic mean of precision and recall
- **ROC-AUC** ‚Äî overall ranking ability across thresholds

**Key results (example)**:

| Model | Accuracy | Precision | Recall | F1-score | ROC-AUC |
|-------|----------|-----------|--------|----------|---------|
| Logistic Regression (final) | 0.85 | 0.87 | 0.84 | 0.857 | 0.926 |

> These are example values from a completed run. Exact numbers may vary slightly on reruns.

---

## üî¨ Model Selection Justification

- Logistic Regression was selected as the final model because:
  - It meets the internship requirement to use simpler/interpretable models.
  - It performed best among the allowed models on overall evaluation metrics (Accuracy, F1, ROC-AUC).
  - It is easy to explain to stakeholders and clinicians.

Random Forest had slightly higher ROC-AUC in experiments but was excluded as per task constraints.

---

## üßæ How to Run (Local)

1. **Clone repository**

```bash
git clone https://github.com/<your-username>/<repo-name>.git
cd <repo-name>
```

2. **Create a virtual environment & install dependencies**

```bash
python -m venv venv
source venv/bin/activate   # Linux / macOS
venv\Scripts\activate     # Windows
pip install -r requirements.txt
```

3. **Place the dataset** in `data/heart_disease.csv` (or update path in notebook).

4. **Open and run the notebook**

```bash
jupyter notebook notebooks/HeartDisease_Model.ipynb
# or
jupyter lab
```

5. **Run all cells** to reproduce results and build the model.

---

## üß∞ How to Use the Saved Model (Inference)

The model artifact saved by the notebook contains:

```python
{
  'model_name': 'Logistic Regression',
  'model': <sklearn LogisticRegression object>,
  'scaler': <sklearn StandardScaler object>,
  'feature_columns': [ ... ]
}
```

Example code to load and predict:

```python
import joblib
import pandas as pd

artifact = joblib.load('model/HeartDisease_LogisticModel.pkl')
model = artifact['model']
scaler = artifact['scaler']
features = artifact['feature_columns']

# example input as dict (keys must match feature_columns order)
sample = {
    'age': 63,
    'sex': 1,
    'cp': 3,
    'trestbps': 145,
    'chol': 233,
    'fbs': 1,
    'restecg': 0,
    'thalach': 150,
    'exang': 0,
    'oldpeak': 2.3,
    'slope': 0,
    'ca': 0,
    'thal': 1
}

x = pd.DataFrame([sample])[features]
x_scaled = scaler.transform(x)
prob = model.predict_proba(x_scaled)[0][1]
label = model.predict(x_scaled)[0]

print('Predicted label:', label)
print('Predicted probability of disease:', prob)
```

---

## üì¶ Requirements (requirements.txt)

```
pandas
numpy
matplotlib
seaborn
scikit-learn
joblib
jupyter
```

---

## üñº Visualizations

The notebook produces and saves the following images (recommended to include them in `/images` for README):

- `roc_curve.png` ‚Äî ROC curve for the final model
- `confusion_matrix.png` ‚Äî Confusion matrix heatmap
- `correlation_heatmap.png` ‚Äî feature correlation map

Include these images in the README with `![alt text](images/roc_curve.png)` to make your repo visually appealing.

---

## üîê Ethics & Limitations

- **Medical disclaimer:** This model is for **educational purposes only** and not for clinical diagnosis. It should not replace professional medical advice.
- **Bias & fairness:** Check for dataset biases (age, gender, ethnicity) before deploying. Models trained on limited datasets may not generalize.
- **Data privacy:** Ensure no PHI (Personal Health Information) is stored in the public repository.

---

## üî≠ Future Improvements

- Use K-fold cross-validation and grid search for hyperparameter tuning
- Calibrate predicted probabilities (Platt scaling or isotonic regression)
- Use feature selection or regularization (L1/L2) to reduce overfitting
- Add SHAP or LIME explanations to improve interpretability
- If allowed: try ensemble methods and XGBoost for performance comparison

---

## üßæ References

- scikit-learn documentation ‚Äî https://scikit-learn.org
- Example heart disease datasets like UCI Heart Disease Dataset (for reference)

---

## ‚úâÔ∏è Contact

**Mohammed Naveeduddin**  
Edulumos Internship ‚Äî Data Science / Machine Learning

If you have questions, suggestions, or collaboration ideas, feel free to reach out.

---

*Made with ‚ù§Ô∏è for Edulumos Internship Task 02*

